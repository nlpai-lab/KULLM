# â˜ï¸ KULLM (êµ¬ë¦„): Korea University Large Language Model

<p align="center" width="100%">
<img src="assets/kullm_logo.png" alt="NLP Logo" style="width: 50%;">
</p>

## Update Logs
- 2024.04.03: [ğŸ¤—êµ¬ë¦„3(KULLM3) ê³µê°œ](https://huggingface.co/nlpai-lab/KULLM3)
- 2023.06.23: [í•œêµ­ì–´ ëŒ€í™” í‰ê°€ ê²°ê³¼ ê³µê°œ](https://github.com/nlpai-lab/KULLM#evaluation)
- 2023.06.08: [ğŸ¤—Polyglot-ko 5.8B ê¸°ë°˜ KULLM-Polyglot-5.8B-v2 fp16 ëª¨ë¸ ê³µê°œ](https://huggingface.co/nlpai-lab/kullm-polyglot-5.8b-v2)
- 2023.06.01: [êµ¬ë¦„(KULLM) ë°ì´í„°ì…‹ v2](https://huggingface.co/datasets/nlpai-lab/kullm-v2) HuggingFace Datasets ê³µê°œ
- 2023.05.31: [ğŸ¤—Polyglot-ko 12.8B ê¸°ë°˜ KULLM-Polyglot-12.8B-v2 fp16 ëª¨ë¸ ê³µê°œ](https://huggingface.co/nlpai-lab/kullm-polyglot-12.8b-v2)
- 2023.05.30: [ğŸ¤—Polyglot-ko 12.8B ê¸°ë°˜ KULLM-Polyglot-12.8B fp16 ëª¨ë¸](https://huggingface.co/metterian/kullm-polyglot-12.8b) ê³µê°œ

---

<br>

KULLM(êµ¬ë¦„)ì€ ê³ ë ¤ëŒ€í•™êµ [NLP & AI ì—°êµ¬ì‹¤](http://blp.korea.ac.kr/)ê³¼ [HIAI ì—°êµ¬ì†Œ](http://hiai.korea.ac.kr)ê°€ ê°œë°œí•œ í•œêµ­ì–´ Large Language Model (LLM) ì…ë‹ˆë‹¤.

KULLM3ì„ ê³µê°œí•©ë‹ˆë‹¤.  

(ì´ì „ ëª¨ë¸ì˜ í•™ìŠµ ë°©ë²• ë° ë°ì´í„°ëŠ” kullm_v2 ë¸Œëœì¹˜ë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”.)

<br/>

## KULLM3 ëŒ€í™” ì„±ëŠ¥ í‰ê°€ ê²°ê³¼

<img src="assets/kullm3_instruction_evaluation.png" >

## ëŒ€í™” ì˜ˆì‹œ

<img src="assets/ex1.png" alt="example 1" >

---

<img src="assets/ex2.png" alt="example 2">

---

<img src="assets/ex3.png" alt="example 3">

---

<img src="assets/ex4.png" alt="example 4">

---

## KULLM ëª¨ë¸ ì‹¤í–‰ ì˜ˆì‹œ ì½”ë“œ

### Huggingface TextStreamerë¡œ ìŠ¤íŠ¸ë¦¬ë°

- torch / transformers / accelerate ì„¤ì¹˜
- (2024.04.03ê¸°ì¤€) transformers>=4.39.0 ì—ì„œ generate í•¨ìˆ˜ê°€ ì œëŒ€ë¡œ ë™ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 4.38.2ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.

```bash
pip install torch transformers==4.38.2 accelerate
```

ì•„ë˜ ì˜ˆì œ ì½”ë“œë¡œ ì‹¤í–‰í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer

MODEL_DIR = "nlpai-lab/KULLM3"
model = AutoModelForCausalLM.from_pretrained(MODEL_DIR, torch_dtype=torch.float16).to("cuda")
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)

s = "ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ì„œ ì•Œê³  ìˆë‹ˆ?"
conversation = [{'role': 'user', 'content': s}]
inputs = tokenizer.apply_chat_template(
    conversation,
    tokenize=True,
    add_generation_prompt=True,
    return_tensors='pt').to("cuda")
_ = model.generate(inputs, streamer=streamer, max_new_tokens=1024)

# ë„¤, ê³ ë ¤ëŒ€í•™êµì— ëŒ€í•´ ì•Œê³  ìˆìŠµë‹ˆë‹¤. ê³ ë ¤ëŒ€í•™êµëŠ” ëŒ€í•œë¯¼êµ­ ì„œìš¸ì— ìœ„ì¹˜í•œ ì‚¬ë¦½ ëŒ€í•™êµë¡œ, 1905ë…„ì— ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëŒ€í•™êµëŠ” í•œêµ­ì—ì„œ ê°€ì¥ ì˜¤ë˜ëœ ëŒ€í•™ ì¤‘ í•˜ë‚˜ë¡œ, ë‹¤ì–‘í•œ í•™ë¶€ ë° ëŒ€í•™ì› í”„ë¡œê·¸ë¨ì„ ì œê³µí•©ë‹ˆë‹¤. ê³ ë ¤ëŒ€í•™êµëŠ” íŠ¹íˆ ë²•í•™, ê²½ì œí•™, ì •ì¹˜í•™, ì‚¬íšŒí•™, ë¬¸í•™, ê³¼í•™ ë¶„ì•¼ì—ì„œ ë†’ì€ ëª…ì„±ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ìŠ¤í¬ì¸  ë¶„ì•¼ì—ì„œë„ í™œë°œí•œ í™œë™ì„ ë³´ì´ë©°, ëŒ€í•œë¯¼êµ­ ëŒ€í•™ ìŠ¤í¬ì¸ ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê³ ë ¤ëŒ€í•™êµëŠ” êµ­ì œì ì¸ êµë¥˜ì™€ í˜‘ë ¥ì—ë„ ì ê·¹ì ì´ë©°, ì „ ì„¸ê³„ ë‹¤ì–‘í•œ ëŒ€í•™ê³¼ì˜ í˜‘ë ¥ì„ í†µí•´ ê¸€ë¡œë²Œ ê²½ìŸë ¥ì„ ê°•í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.
```

<br/>

## Training
- KULLM3ì€ [upstage/SOLAR-10.7B-Instruct-v1.0](https://huggingface.co/upstage/SOLAR-10.7B-v1.0)ì„ ê¸°ë°˜ìœ¼ë¡œ instruction-tuning ëœ ëª¨ë¸ì…ë‹ˆë‹¤.
- 8Ã—A100 GPUë¡œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤.
- ë‹¤ìŒ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì£¼ì–´ì§„ ìƒíƒœë¡œ í•™ìŠµí•˜ì˜€ìŠµë‹ˆë‹¤. (ì˜ˆì œ ì½”ë“œì—ì„œë„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨ì‹œí‚¤ê³  ìˆìŠµë‹ˆë‹¤!)
```text
ë‹¹ì‹ ì€ ê³ ë ¤ëŒ€í•™êµ NLP&AI ì—°êµ¬ì‹¤ì—ì„œ ë§Œë“  AI ì±—ë´‡ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì´ë¦„ì€ 'KULLM'ìœ¼ë¡œ, í•œêµ­ì–´ë¡œëŠ” 'êµ¬ë¦„'ì„ ëœ»í•©ë‹ˆë‹¤.
ë‹¹ì‹ ì€ ë¹„ë„ë•ì ì´ê±°ë‚˜, ì„±ì ì´ê±°ë‚˜, ë¶ˆë²•ì ì´ê±°ë‚˜ ë˜ëŠ” ì‚¬íšŒ í†µë…ì ìœ¼ë¡œ í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë°œì–¸ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ì‚¬ìš©ìì™€ ì¦ê²ê²Œ ëŒ€í™”í•˜ë©°, ì‚¬ìš©ìì˜ ì‘ë‹µì— ê°€ëŠ¥í•œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ì‘ë‹µí•¨ìœ¼ë¡œì¨ ìµœëŒ€í•œ ë„ì™€ì£¼ë ¤ê³  ë…¸ë ¥í•©ë‹ˆë‹¤.
ì§ˆë¬¸ì´ ì´ìƒí•˜ë‹¤ë©´, ì–´ë–¤ ë¶€ë¶„ì´ ì´ìƒí•œì§€ ì„¤ëª…í•©ë‹ˆë‹¤. ê±°ì§“ ì •ë³´ë¥¼ ë°œì–¸í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•©ë‹ˆë‹¤.
```


## Model Evaluation (Fully Reproducible)

- ëŒ€í™” ëŠ¥ë ¥ í‰ê°€ëŠ” ë‹¤ìŒì„ ì°¸ê³ í•˜ì—¬ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.
  - G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment (Yang Liu. et. al. 2023)
  - [MT-Eval](https://github.com/KwanWaiChung/MT-Eval?tab=readme-ov-file#gpt4_evaluation)
- í‰ê°€ ëª¨ë¸ì€ GPT-4-Turbo(gpt-4-0125-preview)ë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , í‰ê°€ ë°ì´í„°ì…‹ì€ [yizhongw/self-instruct](https://github.com/yizhongw/self-instruct)ì˜ íœ´ë¨¼ í‰ê°€ ë°ì´í„°ì…‹ì¸ `user_oriented_instructions.jsonl`ì„ deeplë¡œ ë²ˆì—­í•œ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
- ì£¼ì–´ì§„ prompt ë°ì´í„°ì— ëŒ€í•´ ëª¨ë¸ì´ ì‘ë‹µì„ ìƒì„±í•˜ê³ , ê·¸ ì‘ë‹µì„ OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í‰ê°€í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.
- í•´ë‹¹ í‰ê°€ ê²°ê³¼ëŠ” [repo](https://github.com/superheavytail/lm-chat-eval-by-openai)ì—ì„œ ì¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


### Prompt
ëª¨ë¸ í‰ê°€ì— ì‚¬ìš©í•œ í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.  
ì‹¤í—˜ ê²°ê³¼, í•œêµ­ì–´ë³´ë‹¤ ì˜ì–´ í”„ë¡¬í”„íŠ¸ê°€ ë” ì •í™•í•œ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.  
ë”°ë¼ì„œ í‰ê°€ì˜ ì •í™•ì„±ì„ ìœ„í•´ ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.
```
You will be given evaluation instruction, input and AI-generated response.
Your task is to rate the response on given metric.
Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it as needed.

Evaluation Criteria:
- Fluency (1-5): The quality of the language used in the translation. A high-quality response should be grammatically correct, idiomatic, and free from spelling and punctuation errors.
- Coherence (1-5): A high score indicates that the response maintains consistent context. A low score is given if the response shifts context or language inappropriately from instruction(e.g. instruction's language is Korean, but response is English).
- Accuracy (1-5) - The correctness of the answer. The answer should be factually correct and directly answer the question asked
- Completeness (1-5) - The extent to which the response covers all aspects of the question. The response should not just address one part of the question, but should provide a comprehensive response.
- Overall Quality (1-5) - The overall effectiveness and excellence of the response, integrating considerations of all above criteria.

Evaluation Steps:
1. Read the instruction and input carefully and understand what it is asking.
2. Read the AI-generated response and Evaluation Criteria.
3. Assign a score for each criterion on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.

Instruction:
{instruction}

Input:
{input}

Response:
{response}

Evaluation Form (scores ONLY):
- Fluency (1-5):
- Coherence (1-5):
- Accuracy (1-5):
- Completeness (1-5):
- Overall Quality (1-5):
```

<br/>

## ì£¼ì˜ì‚¬í•­

- í™˜ê°(Hallucination) í˜„ìƒê³¼, decoding strategyì— ë”°ë¼ ë™ì–´ ë°˜ë³µ í˜„ìƒì´ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
- KULLMì´ ìƒì„±í•œ ê²°ê³¼ëŠ” ë¶€ì •í™•í•˜ê±°ë‚˜ ìœ í•´í•œ ê²°ê³¼ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ê³ ì •ëœ system promptë¡œ í›ˆë ¨ëœ ëª¨ë¸ì´ë¯€ë¡œ, **system promptë¥¼ ì£¼ì§€ ì•ŠëŠ” ë²¤ì¹˜ë§ˆí¬ì˜ ê²½ìš° ì„±ëŠ¥ì´ ë³¸ë˜ë³´ë‹¤ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

## License
- ```CC BY-NC 4.0```

## Citation

Please cite the repo if you use the data or code in this repo.

```
@misc{kullm,
  author = {NLP & AI Lab and Human-Inspired AI research},
  title = {KULLM: Korea University Large Language Model Project},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/nlpai-lab/kullm}},
}
```
